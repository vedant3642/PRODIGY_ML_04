# ‚úã Hand Gesture Recognition for Human-Computer Interaction
This project focuses on building a machine learning-based system that can recognize various hand gestures in real time or from static images. The system uses computer vision for hand detection and preprocessing, and a trained classifier (CNN/SVM) for gesture classification.

## Visualization of CNN Architecture
![Clustering Visualization](images/cluster_image.jpg) 

## üîç Features:
Real-time video and static image input support

Preprocessing: skin filtering, contour detection, hand segmentation

ML/CNN-based gesture classification

Modular design for integration into gesture-controlled applications

## üíª Tech Stack:
![Python](https://img.shields.io/badge/Python-3.8%2B-yellowgreen)
![OpenCV](https://img.shields.io/badge/OpenCV-4.x-red)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-lightblue)
![MediaPipe](https://img.shields.io/badge/MediaPipe-0.10%2B-blueviolet)
![Scikit-learn](https://img.shields.io/badge/Scikit--Learn-1.0%2B-orange)
![SVM](https://img.shields.io/badge/Model-CNN-blue)

[![License](https://img.shields.io/badge/License-MIT-blue?style=flat-square&logo=github&labelColor=blue&color=lightgrey&logoWidth=20)](LICENSE)
